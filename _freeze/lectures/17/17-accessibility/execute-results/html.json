{
  "hash": "d9bfc948947c4715b0c96e47f859c801",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Accessibility\"\nsubtitle: Lecture 17\nformat: \n  revealjs:\n    fig-align: center\n    fig-width: 5\n    fig-asp: 0.618\n---\n\n\n# Warm-up\n\n## Announcements\n\n-   ...\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(countdown)\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggthemes)\nlibrary(coloratio) # devtools::install_github(\"matt-dray/coloratio\")\n```\n:::\n\n\n# Do you remember?\n\n## Flatten the curve\n\n![](images/flatten-the-curve.jpeg){fig-align=\"center\"}\n\n::: aside\nSource: The New York Times. [Flattening the Coronavirus Curve](https://www.nytimes.com/article/flatten-curve-coronavirus.html)\n:::\n\n## Exponential spread\n\n![](images/wapo-covid.png){fig-align=\"center\" width=\"1201\"}\n\n::: aside\nSource: The Washington Post. [Why outbreaks like coronavirus spread exponentially, and how to \"flatten the curve\"](https://www.washingtonpost.com/graphics/2020/world/corona-simulator/)\n:::\n\n## JHU COVID-19 Dashboard\n\n![](images/jhu-dashboard.png){fig-align=\"center\" width=\"1400\"}\n\n::: aside\nSource: [COVID-19 Dashboard by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU)](https://coronavirus.jhu.edu/map.html)\n:::\n\n## Think back {.center}\n\n::: task\nWhat do they all have in common?\n:::\n\n## Accessible COVID-19 statistics tracker\n\n\n```{=html}\n<iframe width=\"1000\" height=\"500\" src=\"https://cvstats.net/\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen data-external=\"1\">\n</iframe>\n```\n\n::: aside\nSource: [Accessible COVID-19 statistics tracker](https://cvstats.net/#page-top)\n:::\n\n# Accessibility and screen readers\n\n## Alternative text\n\n> It is read by screen readers in place of images allowing the content and function of the image to be accessible to those with visual or certain cognitive disabilities.\n>\n> It is displayed in place of the image in browsers if the image file is not loaded or when the user has chosen not to view images.\n>\n> It provides a semantic meaning and description to images which can be read by search engines or be used to later determine the content of the image from page context alone.\n\n::: aside\nSource: [WebAIM](https://webaim.org/techniques/alttext/)\n:::\n\n## Alt and surrounding text {.smaller}\n\n```         \n\"CHART TYPE of TYPE OF DATA where REASON FOR INCLUDING CHART`\n\n+ Link to data source somewhere in the text\n```\n\n. . .\n\n-   `CHART TYPE`: It's helpful for people with partial sight to know what chart type it is and gives context for understanding the rest of the visual.\n\n. . .\n\n-   `TYPE OF DATA`: What data is included in the chart? The x and y axis labels may help you figure this out.\n\n. . .\n\n-   `REASON FOR INCLUDING CHART`: Think about why you're including this visual. What does it show that's meaningful. There should be a point to every visual and you should tell people what to look for.\n\n. . .\n\n-   `Link to data source`: Don't include this in your alt text, but it should be included somewhere in the surrounding text.\n\n::: source\nSource: [Writing Alt Text for Data Visualization](https://medium.com/nightingale/writing-alt-text-for-data-visualization-2a218ef43f81)\n:::\n\n## Data {.smaller}\n\n-   Registered nurses by state and year\n-   Number of nurses, salaries, employment\n-   Source: [TidyTuesday](https://github.com/rfordatascience/tidytuesday/tree/master/data/2021/2021-10-05)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnurses <- read_csv(\"data/nurses.csv\") |> janitor::clean_names()\nnames(nurses)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"state\"                                       \n [2] \"year\"                                        \n [3] \"total_employed_rn\"                           \n [4] \"employed_standard_error_percent\"             \n [5] \"hourly_wage_avg\"                             \n [6] \"hourly_wage_median\"                          \n [7] \"annual_salary_avg\"                           \n [8] \"annual_salary_median\"                        \n [9] \"wage_salary_standard_error_percent\"          \n[10] \"hourly_10th_percentile\"                      \n[11] \"hourly_25th_percentile\"                      \n[12] \"hourly_75th_percentile\"                      \n[13] \"hourly_90th_percentile\"                      \n[14] \"annual_10th_percentile\"                      \n[15] \"annual_25th_percentile\"                      \n[16] \"annual_75th_percentile\"                      \n[17] \"annual_90th_percentile\"                      \n[18] \"location_quotient\"                           \n[19] \"total_employed_national_aggregate\"           \n[20] \"total_employed_healthcare_national_aggregate\"\n[21] \"total_employed_healthcare_state_aggregate\"   \n[22] \"yearly_total_employed_state_aggregate\"       \n```\n\n\n:::\n:::\n\n\n## Alt text for bar charts\n\n\n::: {.cell}\n\n:::\n\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-4-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n-   Provide title and axis labels\n-   Briefly describe the chart and give a summary of any trends it displays\n-   Convert bar charts to accessible tables or lists\n-   Avoid describing visual attributes of the bars (e.g., dark blue, gray, yellow) unless there's an explicit need to do so\n:::\n:::\n\n## Developing the alt text {.smaller}\n\n-   Total employed registered nurses in three states over time.\n\n. . .\n\n-   Total employed registered nurses in California, New York, and North Carolina, in 2000, 2010, and 2020.\n\n. . .\n\n-   A bar chart of total employed registered nurses in California, New York, and North Carolina, in 2000, 2010, and 2020, showing increasing numbers of nurses over time.\n\n. . .\n\n-   The figure is a bar chart titled \"Total employed Registered Nurses\" that displays the numbers of registered nurses in three states (California, New York, and North Carolina) over a 20 year period, with data recorded in three time points (2000, 2010, and 2020). In each state, the numbers of registered nurses increase over time. The following numbers are all approximate. California started off with 200K registered nurses in 2000, 240K in 2010, and 300K in 2020. New York had 150K in 2000, 160K in 2010, and 170K in 2020. Finally North Carolina had 60K in 2000, 90K in 2010, and 100K in 2020.\n\n## Alt text for line graphs\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-5-1.png){width=100%}\n:::\n:::\n\n\n::: task\nWrite alt text for the line graph above.\n:::\n:::\n\n::: {.column width=\"50%\"}\n-   Provide title and axis labels\n-   Briefly describe the graph and give a summary of any trends it displays\n-   Convert data represented in lines to accessible tables or lists where feasible\n-   Avoid describing visual attributes of the lines (e.g., purple, pink) unless there's an explicit need to do so\n:::\n:::\n\n\n```{=html}\n<!--\nThe figure is titled \"Annual median salary of Registered Nurses\". There are three lines on the plot: the top labelled California, the middle New York, the bottom North Carolina. The vertical axis is labelled \"Annual median salary\", beginning with $40K, up to $120K. The horizontal axis is labelled \"Year\", beginning with couple years before 2000 up to 2020. The following numbers are all approximate. In the graph, the California line begins around $50K in 1998 and goes up to  $120K in 2020. The increase is steady, except for stalling for about couple years between 2015 to 2017. The New York line also starts around $50K, just below where the California line starts, and steadily goes up to $90K. And the North Carolina line starts around $40K and steadily goes up to $70K.\n-->\n```\n\n## Alt text for scatter plots {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n\n\n::: task\nWrite alt text for the scatter plot above.\n:::\n:::\n\n::: {.column width=\"50%\"}\nScatter plots are among the more difficult graphs to describe, especially if there is a need to make specific data point accessible.\n\n-   Identify the image as a scatter plot\n-   Provide the title and axis labels\n-   Focus on the overall trend\n-   If it's necessary to be more specific, convert the data into an accessible table\n:::\n:::\n\n## Recommended reading {.smaller}\n\n[Accessible Visualization via Natural Language Descriptions: A Four-Level Model of Semantic Content](http://vis.csail.mit.edu/pubs/vis-text-model/)\n\nAlan Lundgard, MIT CSAIL\\\nArvind Satyanarayan, MIT CSAIL\n\nIEEE Transactions on Visualization & Computer Graphics (Proceedings of IEEE VIS), 2021\n\n> To demonstrate how our model can be applied to evaluate the effectiveness of visualization descriptions, we conduct a mixed-methods evaluation with 30 blind and 90 sighted readers, and find that these reader groups differ significantly on which semantic content they rank as most useful. Together, our model and findings suggest that access to meaningful information is strongly reader-specific, and that research in automatic visualization captioning should orient toward descriptions that more richly communicate overall trends and statistics, sensitive to reader preferences.\n\n# Accessibility and colors\n\n## Color scales\n\nUse colorblind friendly color scales (e.g., Okabe Ito, viridis)\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/cbf-color-scale-1.png){width=480}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nnurses_subset |>\n  ggplot(aes(x = year, y = hourly_wage_median, color = state)) +\n  geom_point(size = 2) +\n  ggthemes::scale_color_colorblind() +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(\n    x = \"Year\", y = \"Median hourly wage\", color = \"State\",\n    title = \"Median hourly wage of Registered Nurses\"\n  ) +\n  theme(\n    legend.position = c(0.15, 0.75),\n    legend.background = element_rect(fill = \"white\", color = \"white\")\n    )\n```\n:::\n\n:::\n:::\n\n## The default ggplot2 color scale + deuteranopia\n\n**Deuteranopia:** A type of red-green confusion\n\n::: columns\n::: {.column width=\"40%\"}\n**Default ggplot2 scale**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/default-ggplot2-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n**Default ggplot2 scale with deuteranopia**\n\n![](images/deuteranopia.png){fig-align=\"center\"}\n:::\n:::\n\n## The default ggplot2 color scale + tritanopia\n\n**Tritanopia:** A type of yellow-blue confusion\n\n::: columns\n::: {.column width=\"40%\"}\n**Default ggplot2 scale**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-9-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n**Default ggplot2 scale with tritanopia**\n\n![](images/tritanopia.png){fig-align=\"center\"}\n:::\n:::\n\n## Testing for colorblind friendliness\n\n-   Best way to test is with users (or collaborators) who have these color deficiencies\n\n-   Simulation software also helps, e.g. Sim Daltonism for [Mac](https://michelf.ca/projects/sim-daltonism/) and [PC](https://pcmacstore.com/en/app/693112260/sim-daltonism)\n\n## Color contrast I\n\n-   Background and foreground text should have sufficient contrast to be distinguishable by users with different vision\n\n-   Web app for checking color contrast checking: [Colour Contrast Analyser](https://www.tpgi.com/color-contrast-checker/)\n\n## Color contrast II\n\nA WIP R package for checking for color contrast: [**coloratio**](https://matt-dray.github.io/coloratio)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncr_get_ratio(\"black\", \"white\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 21\n```\n\n\n:::\n\n```{.r .cell-code}\ncr_get_ratio(\"#FFFFFF\", \"#000000\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 21\n```\n\n\n:::\n\n```{.r .cell-code}\ncr_get_ratio(\"black\", \"gray10\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.206596\n```\n\n\n:::\n:::\n\n\n## Double encoding\n\nUse shape *and* color where possible\n\n. . .\n\n::: columns\n::: {.column width=\"40%\"}\n**Default ggplot2 scale**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-11-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n**Default ggplot2 scale with deuteranopia**\n\n![](images/deuteranopia-shape.png){fig-align=\"center\"}\n:::\n:::\n\n## Use direct labeling\n\n-   Prefer direct labeling where color is used to display information over a legend\n\n-   Quicker to read\n\n-   Ensures graph can be understood without reliance on color\n\n## Without direct labeling\n\n::: columns\n::: {.column width=\"40%\"}\n**Default ggplot2 scale**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-12-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n**Default ggplot2 scale with deuteranopia**\n\n![](images/deuteranopia-no-direct-labeling.png){fig-align=\"center\"}\n:::\n:::\n\n## With direct labeling\n\n::: columns\n::: {.column width=\"40%\"}\n**Default ggplot2 scale**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-13-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n**Default ggplot2 scale with deuteranopia**\n\n![](images/deuteranopia-direct-labeling.png){fig-align=\"center\"}\n:::\n:::\n\n## Use whitespace or pattern to separate elements\n\n-   Separate elements with whitespace or pattern\n\n-   Allows for distinguishing between data without entirely relying on contrast between colors\n\n## Without whitespace\n\n::: columns\n::: {.column width=\"40%\"}\n**Default ggplot2 scale**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-14-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n**Default ggplot2 scale with tritanopia**\n\n![](images/tritanopia-no-separate.png){fig-align=\"center\"}\n:::\n:::\n\n## With whitespace\n\n::: columns\n::: {.column width=\"40%\"}\n**Default ggplot2 scale**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-accessibility_files/figure-revealjs/unnamed-chunk-15-1.png){width=100%}\n:::\n:::\n\n:::\n\n::: {.column width=\"60%\"}\n**Default ggplot2 scale with tritanopia**\n\n![](images/tritanopia-with-separate.png){fig-align=\"center\"}\n:::\n:::\n\n## {.center}\n\n::: task\nFind a colorblind friendly color palette other than viridis and those in the colorblindr package. This could be an R package that offers a colorblind friendly color palette or it could be just a palette you find online. Apply it to the scatterplot you previously wrote alt text for.\n:::\n\n# Accessibility and fonts\n\n## Accessibility and fonts\n\n-   Use a font that has been tested for accessibility (e.g., [Atkinson Hyperlegible](https://fonts.google.com/specimen/Atkinson+Hyperlegible))\n\n. . .\n\n-   Keep plot labels and annotations similarly sized as the rest of your text (e.g., `ggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))`)\n\n. . .\n\n::: task\nDemo: Using custom fonts in ggplots!\n:::\n\n## Keep in mind {.center}\n\n::: large\n::: hand\nWhen you design for accessibility, you benefit everyone\n:::\n:::\n\n::: source\nSource: [A Comprehensive Guide to Accessible Data Visualization](https://www.betterment.com/resources/accessible-data-visualization/)\n:::\n\n# Other approaches to accessibility\n\n## Data sonification\n\nData sonification is the presentation of data as sound, i.e., auditory equivalent of data visualization.\n\nExample: <http://playitbyr.org/gettingstarted.html#Idea>\n\n## Data physicalization / haptics\n\nData physicalization is the presentation of data as objects you can touch, i.e., sensory equivalent of data visualization.\n\nExamples: <https://datajournalism.com/read/longreads/lets-get-physical-how-to-represent-data-through-touch>\n\n## Acknowledgements {.smaller}\n\n-   COVID visualization examples:\n\n    -   The New York Times. [Flattening the Coronavirus Curve](https://www.nytimes.com/article/flatten-curve-coronavirus.html)\n    -   The Washington Post. [Why outbreaks like coronavirus spread exponentially, and how to \"flatten the curve\"](https://www.washingtonpost.com/graphics/2020/world/corona-simulator/)\n    -   [COVID-19 Dashboard by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU)](https://coronavirus.jhu.edu/map.html)\n    -   T. Littlefield (2020) [COVID-19 Statistics Tracker](https://cvstats.net)\n\n-   Lundgard, Alan, and Arvind Satyanarayan. [\"Accessible Visualization via Natural Language Descriptions: A Four-Level Model of Semantic Content.\"](https://ieeexplore.ieee.org/abstract/document/9555469) IEEE transactions on visualization and computer graphics (2021).\n\n-   [A Comprehensive Guide to Accessible Data Visualization](https://www.betterment.com/resources/accessible-data-visualization/)\n\n-   Silvia Canelón and Liz Hare. [Revealing Room for Improvement in Accessibility within a Social Media Data Visualization Learning Community](https://spcanelon.github.io/csvConf2021/slides/#1)\n",
    "supporting": [
      "17-accessibility_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}